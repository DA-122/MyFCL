    # todo
    parser.add_argument('--exp_name', type=str, default='test', help='name of this experiment')
    parser.add_argument('--wandb', type=int, default=1, help='1 for using wandb')
    parser.add_argument('--save_dir', type=str, default="", help='save the syn data')
    parser.add_argument('--project', type=str, default="TARGET", help='wandb project')
    parser.add_argument('--group', type=str, default="exp1", help='wandb group')
    parser.add_argument('--seed', type=int, default=2023, help='random seed')

    # federated continual learning settings
    parser.add_argument('--dataset', type=str, default="cifar100", help='which dataset')
    parser.add_argument('--tasks', type=int, default=5, help='num of tasks')
    # todo
    parser.add_argument('--method', type=str, default="finetune", help='choose a learner')
    parser.add_argument('--net', type=str, default="resnet32", help='choose a model')
    parser.add_argument('--com_round', type=int, default=100, help='communication rounds')
    parser.add_argument('--num_users', type=int, default=5, help='num of clients')
    parser.add_argument('--local_bs', type=int, default=128, help='local batch size')
    parser.add_argument('--local_ep', type=int, default=5, help='local training epochs')
    parser.add_argument('--beta', type=float, default=0.5, help='control the degree of label skew')
    parser.add_argument('--frac', type=float, default=1.0, help='the fraction of selected clients')
    parser.add_argument('--nums', type=int, default=8000, help='the num of synthetic data')
    parser.add_argument('--kd', type=int, default=25, help='for kd loss')
    parser.add_argument('--memory_size', type=int, default=300, help='the num of real data per task')


exp_name: test
wandb: 1
save_dir: 
project: TARGET
group: exp1
seed: 2023
dataset: cifar100
tasks: 5

method: finetune
neet: resnet32
com_round: 100
num_users: 5
local_bs: 128
local_ep: 5
beta: 0.5
frac: 1.0
nums: 8000
kd: 25
memory_size: 300